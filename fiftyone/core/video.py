"""
Video frame views.

| Copyright 2017-2021, Voxel51, Inc.
| `voxel51.com <https://voxel51.com/>`_
|
"""
from copy import deepcopy
import logging
import os

from bson import ObjectId

import eta.core.utils as etau

import fiftyone as fo
import fiftyone.core.aggregations as foa
import fiftyone.core.dataset as fod
import fiftyone.core.fields as fof
import fiftyone.core.media as fom
import fiftyone.core.sample as fos
import fiftyone.core.odm as foo
import fiftyone.core.utils as fou
import fiftyone.core.view as fov

fouv = fou.lazy_import("fiftyone.utils.video")


logger = logging.getLogger(__name__)


_DEFAULT_FIELDS_NO_INDEX = [
    "_id",
    "_rand",
    "_media_type",
    "filepath",
    "metadata",
    "tags",
    "frame_id",
]


_DEFAULT_FIELDS = set(_DEFAULT_FIELDS_NO_INDEX)
_DEFAULT_FIELDS.update({"_sample_id", "frame_number"})


class FrameView(fos.SampleView):
    """A frame in a :class:`FramesView`.

    :class:`FrameView` instances should not be created manually; they are
    generated by iterating over :class:`FramesView` instances.

    Args:
        doc: a :class:`fiftyone.core.odm.DatasetSampleDocument`
        view: the :class:`FramesView` that the frame belongs to
        selected_fields (None): a set of field names that this view is
            restricted to
        excluded_fields (None): a set of field names that are excluded from
            this view
        filtered_fields (None): a set of field names of list fields that are
            filtered in this view
    """

    @property
    def sample_id(self):
        """The ID of the sample to which this frame belongs."""
        return str(self._sample_id)

    def save(self):
        super().save()

        # Update source collection
        self._view._sync_source_sample(self)


class FramesView(fov.DatasetView):
    """A :class:`fiftyone.core.view.DatasetView` of frames from a video
    :class:`fiftyone.core.dataset.Dataset`.

    Frames views contain an ordered collection of frames, each of which
    corresponds to a single frame of a video from the source collection.

    Frames retrieved from frames views are returned as :class:`FrameView`
    objects.

    Args:
        source_collection: the
            :class:`fiftyone.core.collections.SampleCollection` from which this
            view was created
        frames_stage: the :class:`fiftyone.core.stages.ToFrames` stage that
            defines how the frames were created
        frames_dataset: the :class:`fiftyone.core.dataset.Dataset` that serves
            the frames in this view
    """

    _SAMPLE_CLS = FrameView

    def __init__(
        self, source_collection, frames_stage, frames_dataset, _stages=None
    ):
        if _stages is None:
            _stages = []

        self._source_collection = source_collection
        self._frames_stage = frames_stage
        self._frames_dataset = frames_dataset
        self.__stages = _stages

    def __copy__(self):
        return self.__class__(
            self._source_collection,
            deepcopy(self._frames_stage),
            self._frames_dataset,
            _stages=deepcopy(self.__stages),
        )

    @property
    def _dataset(self):
        return self._frames_dataset

    @property
    def _root_dataset(self):
        return self._source_collection._root_dataset

    @property
    def _stages(self):
        return self.__stages

    @property
    def _all_stages(self):
        return (
            self._source_collection.view()._all_stages
            + [self._frames_stage]
            + self.__stages
        )

    @property
    def name(self):
        return self.dataset_name + "-frames"

    def _edit_label_tags(self, edit_fcn, label_fields=None):
        # This covers the necessary overrides for both `tag_labels()` and
        # `untag_labels()`. This is important because the App uses
        # `_edit_label_tags()` rather than the public methods to update tags

        if etau.is_str(label_fields):
            label_fields = [label_fields]

        super()._edit_label_tags(edit_fcn, label_fields=label_fields)

        # Update source collection

        if label_fields is None:
            fields = self._frames_dataset._get_label_fields()
        else:
            fields = label_fields

        def sync_fcn(view, field):
            view._edit_label_tags(edit_fcn, label_fields=[field])

        self._sync_source_fcn(sync_fcn, fields)

    def set_values(self, field_name, *args, **kwargs):
        super().set_values(field_name, *args, **kwargs)

        # Update source collection

        field = field_name.split(".", 1)[0]
        self._sync_source(fields=[field])

    def save(self, fields=None):
        if etau.is_str(fields):
            fields = [fields]

        super().save(fields=fields)

        # Update source collection

        #
        # IMPORTANT: we sync the contents of `_frames_dataset`, not `self`
        # here because the `save()` call above updated the dataset, which means
        # this view may no longer have the same contents (e.g., if `skip()` is
        # involved)
        #

        self._sync_source(fields=fields, root=True)

    def reload(self):
        self._root_dataset.reload()

        #
        # Regenerate the frames dataset
        #
        # This assumes that calling `load_view()` when the current patches
        # dataset has been deleted will cause a new one to be generated
        #

        self._frames_dataset.delete()
        _view = self._frames_stage.load_view(self._source_collection)
        self._frames_dataset = _view._frames_dataset

    def _sync_source_sample(self, sample):
        self._sync_source_schema()

        updates = {
            k: v
            for k, v in sample.to_mongo_dict().items()
            if k not in _DEFAULT_FIELDS
        }

        self._source_collection._dataset._frame_collection.update_one(
            {"_id": ObjectId(sample.frame_id)}, {"$set": updates}
        )

    def _sync_source_fcn(self, sync_fcn, fields):
        for field in fields:
            frame_field = self._FRAMES_PREFIX + field
            _, id_path = self._get_label_field_path(field, "id")
            ids = self.values(id_path, unwind=True)
            source_view = self._source_collection.select_labels(
                ids=ids, fields=frame_field
            )
            sync_fcn(source_view, frame_field)

    def _sync_source(self, fields=None, root=False):
        self._sync_source_schema(fields=fields)

        pipeline = []

        if fields is None:
            pipeline.append({"$unset": _DEFAULT_FIELDS_NO_INDEX})
        else:
            pipeline.append({"$project": {f: True for f in fields}})

        pipeline.append(
            {
                "$merge": {
                    "into": self._source_collection._dataset._frame_collection_name,
                    "on": ["_sample_id", "frame_number"],
                    "whenMatched": "merge",
                    "whenNotMatched": "discard",
                }
            }
        )

        collection = self._frames_dataset if root else self
        collection._aggregate(pipeline=pipeline)

    def _sync_source_schema(self, fields=None):
        schema = self.get_field_schema()
        src_schema = self._source_collection.get_frame_field_schema()

        add_fields = []
        delete_fields = []

        if fields is not None:
            # We're syncing specific fields; if they are not present in source
            # collection, add them
            for field_name in fields:
                if field_name not in src_schema:
                    add_fields.append(field_name)
        else:
            # We're syncing all fields; add any missing fields to source
            # collection and delete any source fields that aren't in this view
            for field_name in schema.keys():
                if field_name not in src_schema:
                    add_fields.append(field_name)

            for field_name in src_schema.keys():
                if field_name not in schema:
                    delete_fields.append(field_name)

        for field_name in add_fields:
            field_kwargs = foo.get_field_kwargs(schema[field_name])
            self._source_collection._dataset.add_frame_field(
                field_name, **field_kwargs
            )

        for field_name in delete_fields:
            self._source_collection._dataset.delete_frame_field(field_name)


def make_frames_dataset(
    sample_collection,
    sample_frames=True,
    frames_patt=None,
    size=None,
    min_size=None,
    max_size=None,
    force_sample=False,
    name=None,
):
    """Creates a dataset that contains one sample per video frame in the
    collection.

    The returned dataset will contain all frame-level fields and the ``tags``
    of each video as sample-level fields, as well as a ``frame_id`` field that
    records the ID of the corresponding frame in the input collection.

    When ``sample_frames`` is True (the default), this method samples each
    video in the collection into a directory of per-frame images with the same
    basename as the input video with frame numbers/format specified by
    ``frames_patt``.

    For example, if ``frames_patt = "%%06d.jpg"``, then videos with the
    following paths::

        /path/to/video1.mp4
        /path/to/video2.mp4
        ...

    would be sampled as follows::

        /path/to/video1/
            000001.jpg
            000002.jpg
            ...
        /path/to/video2/
            000001.jpg
            000002.jpg
            ...

    .. note::

        The returned dataset is independent from the source collection;
        modifying it will not affect the source collection.

    Args:
        sample_collection: a
            :class:`fiftyone.core.collections.SampleCollection`
        sample_frames (True): whether to sample the video frames. If False,
            the dataset cannot currently be viewed in the App
        frames_patt (None): a pattern specifying the filename/format to use to
            store the sampled frames, e.g., ``"%%06d.jpg"``. The default value
            is ``fiftyone.config.default_sequence_idx + fiftyone.config.default_image_ext``
        size (None): an optional ``(width, height)`` for each frame. One
            dimension can be -1, in which case the aspect ratio is preserved
        min_size (None): an optional minimum ``(width, height)`` for each
            frame. A dimension can be -1 if no constraint should be applied.
            The frames are resized (aspect-preserving) if necessary to meet
            this constraint
        max_size (None): an optional maximum ``(width, height)`` for each
            frame. A dimension can be -1 if no constraint should be applied.
            The frames are resized (aspect-preserving) if necessary to meet
            this constraint
        force_sample (False): whether to resample videos whose sampled frames
            already exist
        name (None): a name for the returned dataset

    Returns:
        a :class:`fiftyone.core.dataset.Dataset`
    """
    if sample_collection.media_type != fom.VIDEO:
        raise ValueError(
            "'%s' is not a video collection" % sample_collection.name
        )

    # We need frame counts
    sample_collection.compute_metadata()

    if sample_frames:
        if frames_patt is None:
            frames_patt = (
                fo.config.default_sequence_idx + fo.config.default_image_ext
            )

        images_patts, frame_counts, ids_to_sample = _parse_frames_collection(
            sample_collection, frames_patt, force_sample
        )

    #
    # Create dataset with proper schema
    #

    dataset = fod.Dataset(name=name)
    dataset.media_type = fom.IMAGE
    dataset.add_sample_field("_sample_id", fof.ObjectIdField)
    dataset.add_sample_field("frame_id", fof.StringField)

    frame_schema = sample_collection.get_frame_field_schema()
    dataset._sample_doc_cls.merge_field_schema(frame_schema)

    #
    # Convert videos to per-frame images, if requested and necessary
    #

    if sample_frames and ids_to_sample:
        logger.info("Sampling video frames...")
        fouv.sample_videos(
            sample_collection.select(ids_to_sample),
            frames_patt=frames_patt,
            size=size,
            min_size=min_size,
            max_size=max_size,
            force_sample=force_sample,
        )

    #
    # Populate samples
    #

    # This is necessary as some frames may not have `Frame` docs
    _initialize_frames(dataset, sample_collection, sample_frames)

    _merge_frame_labels(dataset, sample_collection)

    _finalize_frames(dataset)

    if sample_frames:
        _finalize_filepaths(dataset, images_patts, frame_counts)

    return dataset


def _parse_frames_collection(sample_collection, frames_patt, force_sample):
    sample_ids, video_paths, frame_counts = sample_collection.aggregate(
        [
            foa.Values("id"),
            foa.Values("filepath"),
            foa.Values("metadata.total_frame_count"),
        ]
    )

    images_patts = []
    ids_to_sample = []
    for sample_id, video_path in zip(sample_ids, video_paths):
        images_patt, found = _prep_for_sampling(video_path, frames_patt)
        images_patts.append(images_patt)
        if not found or force_sample:
            ids_to_sample.append(sample_id)

    return images_patts, frame_counts, ids_to_sample


def _initialize_frames(dataset, src_collection, sample_frames):
    project_fields = ["_sample_id", "frame_number", "tags"]
    if not sample_frames:
        project_fields.append("filepath")

    pipeline = src_collection._pipeline(detach_frames=True)
    pipeline.extend(
        [
            {
                "$set": {
                    "_sample_id": "$_id",
                    "frame_number": {
                        "$range": [
                            1,
                            {"$add": ["$metadata.total_frame_count", 1]},
                        ]
                    },
                }
            },
            {"$project": {f: True for f in project_fields}},
            {"$unset": "_id"},
            {"$unwind": "$frame_number"},
            {"$out": dataset._sample_collection_name},
        ]
    )

    src_collection._dataset._aggregate(pipeline=pipeline, attach_frames=False)


def _merge_frame_labels(dataset, src_collection):
    # We'll use this index to merge both now and in the opposite direction
    # when syncing the source collection
    index_spec = [("_sample_id", 1), ("frame_number", 1)]
    dataset._sample_collection.create_index(index_spec, unique=True)

    pipeline = src_collection._pipeline(frames_only=True)
    pipeline.extend(
        [
            {"$set": {"frame_id": {"$toString": "$_id"}}},
            {"$unset": "_id"},
            {
                "$merge": {
                    "into": dataset._sample_collection_name,
                    "on": ["_sample_id", "frame_number"],
                    "whenMatched": "merge",
                    "whenNotMatched": "insert",
                }
            },
        ]
    )

    src_collection._dataset._aggregate(pipeline=pipeline, attach_frames=False)


def _finalize_frames(dataset):
    dataset._sample_collection.update_many(
        {}, [{"$set": {"_media_type": "image", "_rand": {"$rand": {}}}}]
    )


def _finalize_filepaths(dataset, images_patts, frame_counts):
    filepaths = []
    for images_patt, frame_count in zip(images_patts, frame_counts):
        filepaths.extend(images_patt % fn for fn in range(1, frame_count + 1))

    dataset.set_values("filepath", filepaths)


def _prep_for_sampling(inpath, frames_patt):
    outdir = os.path.splitext(inpath)[0]
    outpatt = os.path.join(outdir, frames_patt)

    # If the first frame exists, assume the video has already been sampled
    found = os.path.exists(outpatt % 1)

    return outpatt, found
