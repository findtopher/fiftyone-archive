# Custom Dataset Examples

FiftyOne datasets are composed of `fiftyone.core.sample.Sample` instances, and
FiftyOne provides the ability for you to construct your own dataset manually by
providing samples or their constituent fields in a variety of common formats.

## Building datasets from scratch

The most flexible way to create a FiftyOne dataset is to manually construct
your own `fiftyone.core.sample.Sample` instances.

The following example demonstrates the construction of a dataset with ground
truth labels stored in a `ground_truth` field:

```py
import fiftyone as fo

# List of class labels
classes = ["cat", "dog"]

# A list of `(image_path, target)` tuples
samples = [("/path/to/cat.jpg", 0), ("/path/to/dog.png", 1)]

# Construct your dataset manually
_samples = []
for image_path, target in samples:
    _samples.append(
        fo.Sample(
            filepath=image_path,
            tags=["train"],
            ground_truth=fo.Classification(label=classes[target]),
        )
    )

# Create the dataset
dataset = fo.Dataset("catdog")
dataset.add_samples(_samples)

# View summary info about the dataset
print(dataset)

# Print the first few samples in the dataset
print(dataset.view().head())
```

## Image classification datasets

FiftyOne provides native support for working with image classification samples
whose images are stored on disk and whose corresponding predictions are stored
in-memory.

In the code below, the input `samples` can be any iterable that emits
`(image_path, target)` tuples, where:

-   `image_path` is the path to the image on disk

-   `target` is either a label string, or, if `classes` are provided, a class
    ID that can be mapped to a label string via `classes[target]`

For example, `samples` may be a `torch.utils.data.Dataset` or an iterable
generated by `tf.data.Dataset.as_numpy_iterator()`.

If your samples do not fit this schema, you can use the
`fiftyone.Dataset.from_labeled_image_samples()` factory method to provide your
own `fiftyone.utils.data.LabeledImageSampleParser` to parse your samples.

```py
import fiftyone as fo

# List of class labels
classes = ...

# A list of `(image_path, target)` tuples
samples = ...

# Create the dataset
dataset = fo.Dataset.from_image_classification_samples(
    samples, classes=classes
)

# View summary info about the dataset
print(dataset)

# Print the first few samples in the dataset
print(dataset.view().head())
```

## Image detection datasets

FiftyOne provides native support for working with image detection samples whose
images are stored on disk and whose corresponding detections are stored
in-memory.

In the code below, the input `samples` can be any iterable that emits
`(image_path, detections)` tuples, where:

-   `image_path` is the path to the image on disk

-   `detections` is a list of detections in the following format:

```
[
    {
        "label": <target>,
        "bounding_box": [
            <top-left-x>, <top-left-y>, <width>, <height>
        ],
        "confidence": <optional-confidence>,
    },
    ...
]
```

where `target` is either a label string, or, if `classes` are provided, a class
ID that can be mapped to a label string via `classes[label]`, and the bounding
box coordinates are relative values in `[0, 1] x [0, 1]`.

For example, `samples` may be a `torch.utils.data.Dataset` or an iterable
generated by `tf.data.Dataset.as_numpy_iterator()`.

If your samples do not fit this schema, you can use the
`fiftyone.Dataset.from_labeled_image_samples()` factory method to provide your
own `fiftyone.utils.data.LabeledImageSampleParser` to parse your samples.

```py
import fiftyone as fo

# List of class labels
classes = ...

# A list of `(image_path, detections)` tuples
samples = ...

# Create the dataset
dataset = fo.Dataset.from_image_detection_samples(samples, classes=classes)

# View summary info about the dataset
print(dataset)

# Print the first few samples in the dataset
print(dataset.view().head())
```

## Multitask image prediction datasets

FiftyOne provides native support for working with multitask image predictions
samples whose images are stored on disk and whose corresponding labels are
stored in-memory.

In the code below, the input `samples` can be any iterable that emits
`(image_path, image_labels)` tuples, where:

-   `image_path` is the path to the image on disk

-   `image_labels` is an `eta.core.image.ImageLabels` instance or a serialized
    dict representation of one

For example, `samples` may be a `torch.utils.data.Dataset` or an iterable
generated by `tf.data.Dataset.as_numpy_iterator()`.

See https://voxel51.com/docs/api/#types-imagelabels for more information on the
`ImageLabels` format.

If your samples do not fit this schema, you can use the
`fiftyone.Dataset.from_labeled_image_samples()` factory method to provide your
own `fiftyone.utils.data.LabeledImageSampleParser` to parse your samples.

```py
import fiftyone as fo

# A list of `(image_path, image_labels)` tuples
samples = ...

# Create the dataset
dataset = fo.Dataset.from_image_labels_samples(samples)

# View summary info about the dataset
print(dataset)

# Print the first few samples in the dataset
print(dataset.view().head())
```

## Custom labeled image datasets

FiftyOne provides support for working with custom labeled image datasets whose
label formats differ from the native classification, detection, and multitask
structures described above.

In the code below, the input `samples` can be any iterable that emits
`(image_path, label)` tuples, where:

-   `image_path` is the path to the image on disk

-   `label` is a `fiftyone.core.labels.Label` instance containing the image
    labels(s)

If your samples require preprocessing to convert to the above format, you can
provide a custom `fiftyone.utils.data.LabeledImageSampleParser` instance via
the `sample_parser` argument whose
`fiftyone.utils.data.LabeledImageSampleParser.parse_label()` method will be
used to parse the sample labels in the input iterable.

```py
import fiftyone as fo
from fiftyone.utils.data import LabeledImageSampleParser


class MyLabeledImageSampleParser(LabeledImageSampleParser):
    """Your custom sample parser class."""

    def parse_label(self, sample):
        """Parses the label from the given sample.

        Args:
            sample: the sample

        Returns:
            a :class:`fiftyone.core.labels.Label` instance
        """
        # @todo: parse the sample and return the label in the correct format
        pass


# A list of `(image_path, your_custom_labels)` tuples
samples = ...

# The sample parser to use to parse the samples
sample_parser = MyLabeledImageSampleParser()

# Create the dataset
dataset = fo.Dataset.from_labeled_image_samples(
    samples, sample_parser=sample_parser
)

# View summary info about the dataset
print(dataset)

# Print the first few samples in the dataset
print(dataset.view().head())
```

## Labeled image datasets stored in-memory

FiftyOne provides support for ingesting labeled image datasets that are stored
as in-memory collections of images and labels.

In the method below, `samples` can be any iterable that emits
`(image_or_path, label)` tuples, where:

-   `image_or_path` is either an image that can be converted to numpy format
    via `np.asarray()` or the path to an image on disk

-   `label` is a `fiftyone.core.labels.Label` instance

If your samples require preprocessing to convert to the above format, you can
provide a custom `fiftyone.utils.data.LabeledImageSampleParser` instance via
the `sample_parser` argument whose
`fiftyone.utils.data.LabeledImageSampleParser.parse()` method will be used to
parse the input samples.

The code below demonstrates using the default
`fiftyone.utils.data.ImageClassificationSampleParser` to ingest an image
classification dataset stored in-memory:

```py
import fiftyone as fo
import fiftyone.utils.data as fod

# List of class labels
classes = ...

# A list of `(img, target)` tuples
samples = ...

# The sample parser to use to parse the samples
sample_parser = fodu.ImageClassificationSampleParser(classes=classes)

# Create the dataset
dataset = fo.Dataset("test-dataset")
dataset.ingest_labeled_image_samples(
    samples,
    dataset_dir="/tmp/dataset",
    sample_parser=sample_parser,
)

# View summary info about the dataset
print(dataset)

# Print the first few samples in the dataset
print(dataset.view().head())
```
